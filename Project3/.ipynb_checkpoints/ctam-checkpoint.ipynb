{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5fecc46-1d5b-47c9-b77d-4445d096dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a2a6d2a-e10a-439f-97ff-a64440ab7c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: AUC Score for split 0: 0.9861161 | Execution time : 14.9251 seconds\n",
      "Split 1: AUC Score for split 1: 0.9860022 | Execution time : 15.3945 seconds\n",
      "Split 2: AUC Score for split 2: 0.9855030 | Execution time : 16.0086 seconds\n",
      "Split 3: AUC Score for split 3: 0.9858564 | Execution time : 16.8945 seconds\n",
      "Split 4: AUC Score for split 4: 0.9856297 | Execution time : 15.0286 seconds\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "for i in range(num_splits):\n",
    "    start_time=time.time()\n",
    "    train_file_path = f'./F24_Proj3_Data/split_{i+1}/train.csv'\n",
    "    test_file_path = f'./F24_Proj3_Data/split_{i+1}/test.csv'\n",
    "    test_y_file_path = f'./F24_Proj3_Data/split_{i+1}/test_y.csv'\n",
    "\n",
    "    # Load data\n",
    "    X_train = pd.read_csv(train_file_path).iloc[:, 3:]\n",
    "    y_train = pd.read_csv(train_file_path).iloc[:, 1]\n",
    "\n",
    "    X_test = pd.read_csv(test_file_path).iloc[:, 2:]\n",
    "    y_test = pd.read_csv(test_y_file_path).iloc[:, 1]\n",
    "\n",
    "    clf = LogisticRegression(penalty=None, solver='lbfgs', max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f'Split {i}: AUC Score for split {i}: {auc_score:.7f} | Execution time : {round(time.time() - start_time, 4)} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0423f6e4-b107-45fb-800f-4da04b7b7d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: Best C: [2.7825594] | Best l1_ratio: [0.1]\n",
      "Split 1: AUC Score for LogisticRegressionCV: 0.9865602 | Execution time: 949.7106 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 31\u001b[0m\n\u001b[1;32m     20\u001b[0m log_reg_cv \u001b[38;5;241m=\u001b[39m LogisticRegressionCV(\n\u001b[1;32m     21\u001b[0m     penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m,          \u001b[38;5;66;03m# ElasticNet penalty\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m,                 \u001b[38;5;66;03m# Use the 'saga' solver for ElasticNet\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m                \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Train the LogisticRegressionCV model\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m log_reg_cv\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get the best value of C and l1_ratio from cross-validation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m best_C \u001b[38;5;241m=\u001b[39m log_reg_cv\u001b[38;5;241m.\u001b[39mC_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1991\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1989\u001b[0m     prefer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1991\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[1;32m   1992\u001b[0m     path_func(\n\u001b[1;32m   1993\u001b[0m         X,\n\u001b[1;32m   1994\u001b[0m         y,\n\u001b[1;32m   1995\u001b[0m         train,\n\u001b[1;32m   1996\u001b[0m         test,\n\u001b[1;32m   1997\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[1;32m   1998\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCs,\n\u001b[1;32m   1999\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[1;32m   2000\u001b[0m         penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty,\n\u001b[1;32m   2001\u001b[0m         dual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual,\n\u001b[1;32m   2002\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[1;32m   2003\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   2004\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   2005\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   2006\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39mclass_weight,\n\u001b[1;32m   2007\u001b[0m         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring,\n\u001b[1;32m   2008\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[1;32m   2009\u001b[0m         intercept_scaling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_scaling,\n\u001b[1;32m   2010\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   2011\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[1;32m   2012\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   2013\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39ml1_ratio,\n\u001b[1;32m   2014\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m   2015\u001b[0m     )\n\u001b[1;32m   2016\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m iter_encoded_labels\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[1;32m   2018\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l1_ratio \u001b[38;5;129;01min\u001b[39;00m l1_ratios_\n\u001b[1;32m   2019\u001b[0m )\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;66;03m# _log_reg_scoring_path will output different shapes depending on the\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# multi_class param, so we need to reshape the outputs accordingly.\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;66;03m# Cs is of shape (n_classes . n_folds . n_l1_ratios, n_Cs) and all the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;66;03m#  (n_classes, n_folds, n_Cs . n_l1_ratios) or\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;66;03m#  (1, n_folds, n_Cs . n_l1_ratios)\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m coefs_paths, Cs, scores, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use LogisticRegressionCV with elastic net penalty. Using cross validation and finding the best C and l1 ratio to speed up training.\n",
    "\n",
    "num_splits = 5\n",
    "cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for i in range(num_splits):\n",
    "    start_time = time.time()\n",
    "    train_file_path = f'./F24_Proj3_Data/split_{2}/train.csv'\n",
    "    test_file_path = f'./F24_Proj3_Data/split_{2}/test.csv'\n",
    "    test_y_file_path = f'./F24_Proj3_Data/split_{2}/test_y.csv'\n",
    "\n",
    "    # Load data\n",
    "    X_train = pd.read_csv(train_file_path).iloc[:, 3:]\n",
    "    y_train = pd.read_csv(train_file_path).iloc[:, 1]\n",
    "\n",
    "    X_test = pd.read_csv(test_file_path).iloc[:, 2:]\n",
    "    y_test = pd.read_csv(test_y_file_path).iloc[:, 1]\n",
    "\n",
    "    # LogisticRegressionCV with 'elasticnet' penalty\n",
    "    log_reg_cv = LogisticRegressionCV(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        l1_ratios=[0.1],  \n",
    "        cv=cv,\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    log_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "    best_C = log_reg_cv.C_\n",
    "    best_l1_ratio = log_reg_cv.l1_ratio_\n",
    "\n",
    "    print(f\"Split {i+1}: Best C: {best_C} | Best l1_ratio: {best_l1_ratio}\")\n",
    "\n",
    "    y_pred_proba = log_reg_cv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f'Split {i+1}: AUC Score for LogisticRegressionCV: {auc_score:.7f} | Execution time: {round(time.time() - start_time, 4)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e264b08-67cc-45f5-815b-d8a25216a9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: AUC Score for LogisticRegressionCV: 0.9869905 | Execution time: 24.5737 seconds\n",
      "Split 2: AUC Score for LogisticRegressionCV: 0.9865600 | Execution time: 25.2715 seconds\n",
      "Split 3: AUC Score for LogisticRegressionCV: 0.9862596 | Execution time: 25.7928 seconds\n",
      "Split 4: AUC Score for LogisticRegressionCV: 0.9867768 | Execution time: 24.2103 seconds\n",
      "Split 5: AUC Score for LogisticRegressionCV: 0.9862021 | Execution time: 25.2237 seconds\n"
     ]
    }
   ],
   "source": [
    "# Use LogisticRegression with best C and l1 ratio we found in the CV approach\n",
    "num_splits = 5\n",
    "\n",
    "for i in range(num_splits):\n",
    "    start_time = time.time()\n",
    "    train_file_path = f'./F24_Proj3_Data/split_{i+1}/train.csv'\n",
    "    test_file_path = f'./F24_Proj3_Data/split_{i+1}/test.csv'\n",
    "    test_y_file_path = f'./F24_Proj3_Data/split_{i+1}/test_y.csv'\n",
    "\n",
    "    # Load data\n",
    "    X_train = pd.read_csv(train_file_path).iloc[:, 3:]\n",
    "    y_train = pd.read_csv(train_file_path).iloc[:, 1]\n",
    "\n",
    "    X_test = pd.read_csv(test_file_path).iloc[:, 2:]\n",
    "    y_test = pd.read_csv(test_y_file_path).iloc[:, 1]\n",
    "\n",
    "    log_reg = LogisticRegression(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        l1_ratio=0.1,  \n",
    "        C=2.7825594,\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f'Split {i+1}: AUC Score for LogisticRegressionCV: {auc_score:.7f} | Execution time: {round(time.time() - start_time, 4)} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
