{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0395d28f-8ba4-4363-9c04-4eba16537ae7",
   "metadata": {},
   "source": [
    "# PSL Coding Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e2be4-e4c7-4c76-b44f-dec0f43325ad",
   "metadata": {},
   "source": [
    "**Members**\n",
    "-  Amy Hwang (ahwang22)\n",
    "-  Christian Tam (cmtam2)\n",
    "-  Monil Kaneria (kaneria2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b0e0c-48ac-44e2-86a0-ee274be431ac",
   "metadata": {},
   "source": [
    "**Contributions:** \n",
    "\n",
    "Christian Tam worked on the following: review and testing \n",
    "\n",
    "Amy Hwang worked on the following: documentation and testing\n",
    "\n",
    "Monil Kaneria worked on the following: functions, data processing, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8078210d-3062-4a0d-b440-b97f6e0ad029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7fb66-bedc-4b11-9a3d-68d7bd3d14d9",
   "metadata": {},
   "source": [
    "## Pegasos Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7425a483-3401-448a-a419-67cfa47a26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_svm(X, y, lambda_param=0.01, epochs=20):\n",
    "    # Initialize parameters\n",
    "    n_samples, n_features = X.shape\n",
    "    beta = np.zeros(n_features)\n",
    "    alpha = 0\n",
    "    t = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the data\n",
    "        X, y = shuffle(X, y, random_state=epoch)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            t += 1\n",
    "            eta_t = 1 / (t * lambda_param)\n",
    "            \n",
    "            # Calculate the gradient and update beta and alpha\n",
    "            if y[i] * (np.dot(X[i].astype(float), beta) + alpha) < 1:\n",
    "                beta = beta - eta_t * ((lambda_param * beta) - (y[i] * X[i].astype(float)))\n",
    "                alpha = alpha + eta_t * y[i]\n",
    "            else:\n",
    "                beta = beta - (eta_t * lambda_param * beta)\n",
    "\n",
    "    return beta, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d515e3b-6918-4af9-a617-b975dc56e139",
   "metadata": {},
   "source": [
    "## Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f16ffa-dbfd-4d43-8fb3-9dca85aac5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, beta, alpha):\n",
    "    return np.where(np.dot(X, beta) + alpha > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270ff8d-8554-4e88-86f7-6b994b7dd6cd",
   "metadata": {},
   "source": [
    "Load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a471b465-9895-4e4d-8b12-5bf694cb9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('coding5_train.csv', header=0)\n",
    "test_data = pd.read_csv('coding5_test.csv', header=0)\n",
    "\n",
    "train_data = train_data.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6484ce-5ca5-49b0-8590-706ceede8c13",
   "metadata": {},
   "source": [
    "Split features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9dff6a1-565b-4eff-bc1b-e7a10f183426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data.iloc[:, -1].values\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412308e7-60e9-4efc-9b1c-15e155902c22",
   "metadata": {},
   "source": [
    "Convert labels to +1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e867db1-7874-4098-af3a-92cc77224b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == 5, 1, -1)\n",
    "y_test = np.where(y_test == 5, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a754951-595c-4d7e-a244-e45a57e781a5",
   "metadata": {},
   "source": [
    "Train the model with the Pegasos algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796c62ba-cec7-4096-8458-20d016e904e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_param = 0.2\n",
    "beta, alpha = pegasos_svm(X_train, y_train, lambda_param=lambda_param, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c2761-692a-4541-b99f-93a811647728",
   "metadata": {},
   "source": [
    "Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f52ebe-1729-4b02-9ca1-d76ab0b82f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = predict(X_train, beta, alpha)\n",
    "test_predictions = predict(X_test, beta, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11168825-a04e-40fa-a555-cbcbf894acb7",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad28e785-d8bf-4984-82eb-c878d7a9e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == -1) & (y_pred == -1))\n",
    "    FP = np.sum((y_true == -1) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == -1))\n",
    "    return np.array([[TP, FN], [FP, TN]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b396a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Training Data:\n",
      "[[100   0]\n",
      " [  0 100]]\n",
      "Confusion Matrix - Test Data:\n",
      "[[295   5]\n",
      " [ 15 285]]\n"
     ]
    }
   ],
   "source": [
    "train_confusion = confusion_matrix(y_train, train_predictions)\n",
    "test_confusion = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(\"Confusion Matrix - Training Data:\")\n",
    "print(train_confusion)\n",
    "\n",
    "print(\"Confusion Matrix - Test Data:\")\n",
    "print(test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd679717-9e7a-435a-ae65-bea14c2897a8",
   "metadata": {},
   "source": [
    "## Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a5ae483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 3.33%\n"
     ]
    }
   ],
   "source": [
    "test_error = np.mean(test_predictions != y_test)\n",
    "print(f\"Test Error: {test_error * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
