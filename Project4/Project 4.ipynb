{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315dfacf-6cb7-4a98-8396-615953a2908f",
   "metadata": {},
   "source": [
    "# (PSL) Project 4: Movie Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de0c2f4-b05a-4810-b33b-1faf1e8064a8",
   "metadata": {},
   "source": [
    "Members:\n",
    "- Amy Hwang (ahwang22)\n",
    "- Christian Tam (cmtam2)\n",
    "- Monil Kaneria (kaneria2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95c0aa-8747-46a5-866b-da4dc52069de",
   "metadata": {},
   "source": [
    "Amy Hwang worked on all parts of the HTML file and application.\n",
    "\n",
    "Monil Kaneria worked on the System I, System II, and the myIBCF function of the HTML file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6b908-c860-4212-b18b-fefdef114c1f",
   "metadata": {},
   "source": [
    "The web link to the movie recommendation application: https://cs598-psl-ahwang22-project4.streamlit.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c60245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Thread 'MainThread': missing ScriptRunContext!\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ed2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "rating_matrix = pd.read_csv(\"I-w9Wo-HSzmUGNNHw0pCzg_bc290b0e6b3a45c19f62b1b82b1699f1_Rmat.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b0ff4",
   "metadata": {},
   "source": [
    "# System I: Recommendation Based on Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dd4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_popular(rating_matrix, top_n=10):\n",
    "    # Calculate popularity (e.g., average rating * number of ratings)\n",
    "    movie_popularity = rating_matrix.apply(lambda col: col.mean(skipna=True) * col.notna().sum(), axis=0)\n",
    "    top_movies = movie_popularity.sort_values(ascending=False).head(top_n)\n",
    "    \n",
    "    return top_movies.index.tolist(), top_movies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed00ee0-3d19-485a-a88a-ff2c5e105b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_popular_ranking, scores = recommend_popular(rating_matrix, rating_matrix.shape[0])\n",
    "all_rank_df = pd.DataFrame(all_popular_ranking)\n",
    "all_rank_df.to_csv(\"all_popular_ranking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586d785",
   "metadata": {},
   "source": [
    "# System II: IBCF-based Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8b949-819d-4c97-8309-4f9bfc2de627",
   "metadata": {},
   "source": [
    "### Step 1: Normalize the rating matrix by centering each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1bf46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize rows by subtracting the mean\n",
    "def normalize_matrix(matrix):\n",
    "    row_means = matrix.mean(axis=1, skipna=True)\n",
    "    \n",
    "    return matrix.sub(row_means, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264b048-92de-4eff-adec-9b9360b1ebcf",
   "metadata": {},
   "source": [
    "### Step 2: Compute the cosine similarity. We ignore similarities computed on less than three user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6470e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity_optimized(matrix):\n",
    "    matrix = normalize_matrix(matrix)\n",
    "    similarity = pd.DataFrame(np.nan, index=matrix.columns, columns=matrix.columns)\n",
    "\n",
    "    for col in matrix.columns:\n",
    "        cs = cosine_similarity_helper(matrix[col], matrix)\n",
    "        similarity.loc[col] = cs\n",
    "\n",
    "    np.fill_diagonal(similarity.values, np.nan)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3746fc2a-40f6-436c-b75d-5128984085d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_helper(movie, all_movies):\n",
    "    # Creating a matrix of the single movie column, copied in the same number of cols as matrix\n",
    "    movie_vals = movie.values\n",
    "    movie_matrix = all_movies.copy()\n",
    "    movie_matrix[:] = movie_vals[:, None]\n",
    "    movie_matrix.columns = all_movies.columns\n",
    "\n",
    "    movie_notna = movie_matrix.notna()\n",
    "    all_movies_notna = all_movies.notna()\n",
    "    \n",
    "    both_ratings_notna = movie_notna.values & all_movies_notna.values\n",
    "    true_counts = both_ratings_notna.sum(axis=0)\n",
    "    mask = true_counts < 3\n",
    "    both_ratings_notna[:, mask] = False\n",
    "\n",
    "    movie_notna_0, all_movies_notna_0 = movie_matrix.where(both_ratings_notna).fillna(0), all_movies.where(both_ratings_notna).fillna(0)\n",
    "    dot = (movie_notna_0 * all_movies_notna_0).sum()\n",
    "    mag_movie, mag_all_movies = np.sqrt(np.sum(movie_notna_0**2, axis=0)), np.sqrt(np.sum(all_movies_notna_0**2, axis=0))\n",
    "\n",
    "    cs = 0.5 * (1 + dot / (mag_movie * mag_all_movies))\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d55d9914-fe8a-4744-8277-efaee1583351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the rating matrix\n",
    "rating_matrix = pd.read_csv(\"I-w9Wo-HSzmUGNNHw0pCzg_bc290b0e6b3a45c19f62b1b82b1699f1_Rmat.csv\", index_col=0)\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = compute_cosine_similarity_optimized(rating_matrix)\n",
    "\n",
    "# Save to CSV\n",
    "similarity_matrix.to_csv(\"similarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69daecdc-e749-4125-9742-45b2dcad0e32",
   "metadata": {},
   "source": [
    "#### Pairwise similarity values from the S matrix for these movies: \"m1\", \"m10\", \"m100\", “m1510”, “m260”, “m3212”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c82920b-f9fc-4d96-bea7-1957a00c7d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             m1       m10      m100  m1510      m260  m3212\n",
      "m1          NaN 0.5121055 0.3919999    NaN 0.7411482    NaN\n",
      "m10   0.5121055       NaN 0.5474583    NaN 0.5343338    NaN\n",
      "m100  0.3919999 0.5474583       NaN    NaN 0.3296943    NaN\n",
      "m1510       NaN       NaN       NaN    NaN       NaN    NaN\n",
      "m260  0.7411482 0.5343338 0.3296943    NaN       NaN    NaN\n",
      "m3212       NaN       NaN       NaN    NaN       NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:.7f}'.format)\n",
    "print(similarity_matrix.loc[[\"m1\", \"m10\", \"m100\", \"m1510\", \"m260\", \"m3212\"],[\"m1\", \"m10\", \"m100\", \"m1510\", \"m260\", \"m3212\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29da6a-b601-4e92-91ce-53c9573bd439",
   "metadata": {},
   "source": [
    "### Step 3: Keep the top 30 similarities in each row, setting the rest to NA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b91f406c-bd33-4776-b94f-8fb84d0c95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_top_n(row, n=30):\n",
    "    # Find the indices of the top 'n' values\n",
    "    top_indices = row.nlargest(n).index\n",
    "\n",
    "    # Set all other values to NaN\n",
    "    return row.where(row.index.isin(top_indices), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f841aa24-f6ed-4ad3-8ed7-1a1314bfb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_copy = similarity_matrix.copy()\n",
    "\n",
    "similarity_top30 = similarity_matrix_copy.apply(keep_top_n, axis=1)\n",
    "similarity_top30.to_csv(\"similarity_matrix_top30.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a68de-c0e0-457d-8e8f-341bf217a804",
   "metadata": {},
   "source": [
    "### Step 4: Define myIBCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2aac99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myIBCF(new_user_ratings):\n",
    "    similarity_url = \"https://raw.githubusercontent.com/hwangsamy1/CS598-PSL/refs/heads/main/Project4/similarity_matrix_top30.csv\"\n",
    "    similarity_matrix = pd.read_csv(similarity_url, index_col=0)\n",
    "    predictions = {}\n",
    "\n",
    "    for movie in similarity_matrix.index:\n",
    "        if pd.isna(new_user_ratings[movie]):\n",
    "            related_movies = similarity_matrix.loc[movie].dropna()\n",
    "            rated_movies = new_user_ratings[~new_user_ratings.isna()]\n",
    "            relevant_movies = related_movies.index.intersection(rated_movies.index)\n",
    "            \n",
    "            if relevant_movies.any():\n",
    "                weights = related_movies.loc[relevant_movies]\n",
    "                ratings = rated_movies.loc[relevant_movies]\n",
    "                prediction = (weights * ratings).sum() / weights.sum()\n",
    "                predictions[movie] = prediction\n",
    "    \n",
    "    # Sort by predicted ratings\n",
    "    sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    predictions_top10_vals = np.array([val for movie, val in sorted_predictions[:10]])\n",
    "    predictions_top10_movies = np.array([movie for movie, val in sorted_predictions[:10]])\n",
    "\n",
    "    notna_count = np.count_nonzero(np.isnan(predictions_top10_vals))\n",
    "    if predictions_top10_vals.size == 0:\n",
    "        notna_count = 10\n",
    "        \n",
    "    if notna_count > 0:\n",
    "        popularity_ranks_url = \"https://raw.githubusercontent.com/hwangsamy1/CS598-PSL/refs/heads/main/Project4/all_popular_ranking.csv\"\n",
    "        popularity_ranks = pd.read_csv(popularity_ranks_url, index_col=0)\n",
    "\n",
    "        mask = ~np.isin(popularity_ranks, predictions_top10_movies)\n",
    "        popular_noranked = popularity_ranks[mask]\n",
    "        remaining_movies = popular_noranked[:notna_count].to_numpy().flatten()\n",
    "\n",
    "        new_predictions = np.full(10, '', dtype='<U10')\n",
    "        new_predictions[:len(predictions_top10_movies)] = predictions_top10_movies\n",
    "\n",
    "        new_predictions[(10-notna_count):] = remaining_movies\n",
    "        return new_predictions\n",
    "\n",
    "    return predictions_top10_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ebac4",
   "metadata": {},
   "source": [
    "# Test our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb8512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Popular Movies:\n",
      " ['m2858', 'm260', 'm1196', 'm1210', 'm2028', 'm1198', 'm593', 'm2571', 'm2762', 'm589']\n",
      "\n",
      "Top 10 IBCF Recommendations for u1181:\n",
      " ['m3732' 'm749' 'm3899' 'm1039' 'm1235' 'm1253' 'm1734' 'm1914' 'm2082'\n",
      " 'm2361']\n",
      "\n",
      "Top 10 IBCF Recommendations for hypothetical user:\n",
      " ['m1017' 'm2805' 'm3269' 'm592' 'm691' 'm74' 'm765' 'm1100' 'm1468'\n",
      " 'm1541']\n"
     ]
    }
   ],
   "source": [
    "# Test the implementation with user u1181\n",
    "if __name__ == \"__main__\":\n",
    "    # Popularity-based recommendations\n",
    "    top_movies, scores = recommend_popular(rating_matrix)\n",
    "    print(\"Top 10 Popular Movies:\\n\", top_movies)\n",
    "\n",
    "    # User \"u1181\" input from the rating matrix\n",
    "    user_ratings_u1181 = rating_matrix.loc[\"u1181\"]\n",
    "\n",
    "    # IBCF-based recommendations for u1181\n",
    "    ibcf_recommendations_u1181 = myIBCF(user_ratings_u1181)\n",
    "    print(\"\\nTop 10 IBCF Recommendations for u1181:\\n\", ibcf_recommendations_u1181)\n",
    "\n",
    "    # Hypothetical user input\n",
    "    user_ratings_hypothetical = pd.Series(index=rating_matrix.columns, dtype=\"float\")\n",
    "    user_ratings_hypothetical[\"m1613\"] = 5\n",
    "    user_ratings_hypothetical[\"m1755\"] = 4\n",
    "\n",
    "    # IBCF-based recommendations for hypothetical user\n",
    "    ibcf_recommendations_hypothetical = myIBCF(user_ratings_hypothetical)\n",
    "    print(\"\\nTop 10 IBCF Recommendations for hypothetical user:\\n\", ibcf_recommendations_hypothetical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e7f2a-93d0-4251-8685-c19c1d688536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
